\relax 
\providecommand\hyper@newdestlabel[2]{}
\newlabel{firstpage}{{}{1}}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{zhou2014regularized}
\citation{Shashua2004PedestrianDF}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Setting of the learning problem}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Three learning problems}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}From classifications to regression: a level-set approach}{3}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Cost-weighted classification decision boundaries estimate the level sets}{3}{subsection.3.1}}
\citation{pirsiavash2009bilinear}
\citation{luo2015support}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Sparse and low-rank decision boundaries}{4}{subsection.3.2}}
\newlabel{sec:fcn class}{{3.2}{4}{Sparse and low-rank decision boundaries}{subsection.3.2}{}}
\newlabel{eq:lowrank}{{1}{4}{Sparse and low-rank decision boundaries}{equation.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Nonparametric learning with ultra-high dimensional matrices}{4}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Main Result I: Classification with high-dimensional matrices}{4}{subsection.4.1}}
\newlabel{subsec:pb1}{{4.1}{4}{Main Result I: Classification with high-dimensional matrices}{subsection.4.1}{}}
\newlabel{eq:large-margin}{{2}{5}{Main Result I: Classification with high-dimensional matrices}{equation.4.2}{}}
\MT@newlabel{eq:large-margin}
\MT@newlabel{eq:large-margin}
\newlabel{eq:opteq}{{3}{5}{Main Result I: Classification with high-dimensional matrices}{equation.4.3}{}}
\MT@newlabel{eq:opteq}
\MT@newlabel{eq:opteq}
\newlabel{eq:formulation}{{4}{5}{Main Result I: Classification with high-dimensional matrices}{equation.4.4}{}}
\MT@newlabel{eq:formulation}
\MT@newlabel{eq:formulation}
\MT@newlabel{eq:opteq}
\newlabel{eq:dualrep}{{5}{5}{Main Result I: Classification with high-dimensional matrices}{equation.4.5}{}}
\MT@newlabel{eq:opteq}
\MT@newlabel{eq:dualrep}
\MT@newlabel{eq:dualrep}
\citation{lin2002support}
\citation{wang2008probability}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Main result II: Level set estimation in matrix space}{6}{subsection.4.2}}
\newlabel{subsec:pb2}{{4.2}{6}{Main result II: Level set estimation in matrix space}{subsection.4.2}{}}
\MT@newlabel{eq:large-margin}
\newlabel{eq:weighted}{{6}{6}{Main result II: Level set estimation in matrix space}{equation.4.6}{}}
\MT@newlabel{eq:weighted}
\MT@newlabel{eq:large-margin}
\MT@newlabel{eq:weighted}
\MT@newlabel{eq:weighted}
\newlabel{eq:levelset}{{7}{6}{Main result II: Level set estimation in matrix space}{equation.4.7}{}}
\newlabel{ass:main}{{1}{6}{Identifiability}{assumption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Main results III: Nonparametric regression function estimation}{6}{subsection.4.3}}
\newlabel{subsec:pb3}{{4.3}{6}{Main results III: Nonparametric regression function estimation}{subsection.4.3}{}}
\newlabel{eq:approx}{{4.3}{6}{Main results III: Nonparametric regression function estimation}{subsection.4.3}{}}
\MT@newlabel{eq:levelset}
\MT@newlabel{eq:levelset}
\@writefile{toc}{\contentsline {section}{\numberline {5}Two examples}{7}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}1-bit matrix denoising}{7}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Multi-task learning}{7}{subsection.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {6}An ADMM algorithm for structural risk minimization}{7}{section.6}}
\newlabel{sec:alg}{{6}{7}{An ADMM algorithm for structural risk minimization}{section.6}{}}
\MT@newlabel{eq:large-margin}
\MT@newlabel{eq:opteq}
\newlabel{eq:opt}{{8}{8}{An ADMM algorithm for structural risk minimization}{equation.6.8}{}}
\MT@newlabel{eq:opt}
\MT@newlabel{eq:opt}
\newlabel{eq:dual1}{{6}{8}{An ADMM algorithm for structural risk minimization}{equation.6.8}{}}
\newlabel{eq:C}{{9}{8}{An ADMM algorithm for structural risk minimization}{equation.6.9}{}}
\MT@newlabel{eq:C}
\MT@newlabel{eq:opt}
\newlabel{eq:dual2}{{10}{8}{An ADMM algorithm for structural risk minimization}{equation.6.10}{}}
\MT@newlabel{eq:dual2}
\MT@newlabel{eq:C}
\MT@newlabel{eq:dual2}
\newlabel{eq:helpeq}{{6}{8}{An ADMM algorithm for structural risk minimization}{equation.6.10}{}}
\MT@newlabel{eq:dual2}
\newlabel{eq:output}{{11}{9}{An ADMM algorithm for structural risk minimization}{equation.6.11}{}}
\MT@newlabel{eq:weighted}
\newlabel{alg:svm}{{1}{9}{An ADMM algorithm for structural risk minimization}{algocfline.1}{}}
\MT@newlabel{eq:output}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces {\bf  Classification algorithm} }}{9}{algocf.1}}
\newlabel{alg:regest}{{2}{9}{An ADMM algorithm for structural risk minimization}{algocfline.2}{}}
\MT@newlabel{eq:weighted}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces {\bf  Level set \& Regression Algorithm} }}{9}{algocf.2}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Extension to nonlinear boundaries}{10}{section.7}}
\newlabel{subsec:nonlinear class}{{7}{10}{Extension to nonlinear boundaries}{section.7}{}}
\newlabel{def:map}{{1}{10}{}{defn.1}{}}
\newlabel{eq:featuremap}{{12}{10}{}{equation.7.12}{}}
\newlabel{eq:linearfcn}{{13}{10}{}{equation.7.13}{}}
\MT@newlabel{eq:featuremap}
\MT@newlabel{eq:linearfcn}
\bibstyle{chicago}
\bibdata{tensor_wang}
\bibcite{lin2002support}{{1}{2002}{{Lin et~al.}}{{Lin, Lee, and Wahba}}}
\bibcite{luo2015support}{{2}{2015}{{Luo et~al.}}{{Luo, Xie, Zhang, and Li}}}
\bibcite{man2005expression}{{3}{2005}{{Man et~al.}}{{Man, Chintagumpala, Visvanathan, Shen, Perlaky, Hicks, Johnson, Davino, Murray, Helman, et~al.}}}
\MT@newlabel{eq:linearfcn}
\newlabel{eq:lowrk}{{14}{11}{Extension to nonlinear boundaries}{equation.7.14}{}}
\MT@newlabel{eq:linearfcn}
\MT@newlabel{eq:lowrk}
\MT@newlabel{eq:lowrank}
\newlabel{def:kernel}{{2}{11}{}{defn.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Numerical experiments}{11}{section.8}}
\bibcite{pirsiavash2009bilinear}{{4}{2009}{{Pirsiavash et~al.}}{{Pirsiavash, Ramanan, and Fowlkes}}}
\bibcite{Shashua2004PedestrianDF}{{5}{2004}{{Shashua et~al.}}{{Shashua, Gdalyahu, and Hayun}}}
\bibcite{wang2008probability}{{6}{2008}{{Wang et~al.}}{{Wang, Shen, and Liu}}}
\bibcite{zhou2014regularized}{{7}{2014}{{Zhou and Li}}{{Zhou and Li}}}
\newlabel{lastpage}{{}{12}}
