\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{Appendices}{1}{section*.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A}Connection to joint matrix decomposition with functional coefficients}{1}{subsection.0.1}}
\newlabel{sec:joint}{{A}{1}{Connection to joint matrix decomposition with functional coefficients}{subsection.0.1}{}}
\newlabel{ex:matrix_decomposition}{{1}{1}{Functionally decomposable matrices}{example.1}{}}
\newlabel{prop:px}{{1}{1}{Low-rank and sparse boundaries}{prop.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {B}Supplementary figures}{3}{subsection.0.2}}
\newlabel{sec:sfigure}{{B}{3}{Supplementary figures}{subsection.0.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S1}{\ignorespaces Finite sample accuracy of matrix classification and regression. (a) simulation setup. (b) classification error with sample size when $d=30$. (c) classification error with matrix dimension when $n=200$. (d) regression error with sample size. The dash line in panels (b)-(d) represent theoretical rate $\mathcal  {O}(n^{-2/3})$, $\mathcal  {O}(\qopname  \relax o{log}d)$, and $\mathcal  {O}(n^{-1/3})$, respectively. \relax }}{3}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:linear}{{S1}{3}{Finite sample accuracy of matrix classification and regression. (a) simulation setup. (b) classification error with sample size when $d=30$. (c) classification error with matrix dimension when $n=200$. (d) regression error with sample size. The dash line in panels (b)-(d) represent theoretical rate $\tO (n^{-2/3})$, $\tO (\log d)$, and $\tO (n^{-1/3})$, respectively. \relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {S2}{\ignorespaces Example outputs returned by {\bf  \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \topsep \z@ \parsep \parskip \itemsep \z@ {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip NonMAR}. Panels (a) and (c) plot the top edges selected by our method. Panels (b) and (d) are scatter plots of the edge connectivity strength (averaged by subregion) versus the estimated response probability. The ground truth function is depicted in dashed curve.\relax }}{3}{figure.caption.3}}
\newlabel{fig:compare3}{{S2}{3}{Example outputs returned by {\bf \small NonMAR}. Panels (a) and (c) plot the top edges selected by our method. Panels (b) and (d) are scatter plots of the edge connectivity strength (averaged by subregion) versus the estimated response probability. The ground truth function is depicted in dashed curve.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {C}Proofs}{4}{subsection.0.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.1}Proof of Proposition\nobreakspace  {}\ref  {thm:identifiability}}{4}{subsubsection.0.3.1}}
\newlabel{eq:excess}{{1}{4}{Proof of Proposition~\ref {thm:identifiability}}{equation.0.1}{}}
\MT@newlabel{eq:excess}
\newlabel{eq:tail2}{{2}{4}{Proof of Proposition~\ref {thm:identifiability}}{Item.1}{}}
\MT@newlabel{eq:tail2}
\MT@newlabel{eq:tail2}
\newlabel{eq:cmultiidentity}{{3}{4}{Proof of Proposition~\ref {thm:identifiability}}{Item.2}{}}
\MT@newlabel{eq:tail2}
\MT@newlabel{eq:cmultiidentity}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.2}Proof of Theorem\nobreakspace  {}\ref  {thm:twobounds}}{5}{subsubsection.0.3.2}}
\MT@newlabel{eq:regression}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.3}Proof of Proposition\nobreakspace  {}\ref  {prop:polynomial}}{6}{subsubsection.0.3.3}}
\newlabel{sec:population}{{C.3}{6}{Proof of Proposition~\ref {prop:polynomial}}{subsubsection.0.3.3}{}}
\newlabel{prop:polynomial}{{2}{6}{Polynomial continuity of inverse links}{prop.2}{}}
\newlabel{eq:concentration}{{2}{6}{Polynomial continuity of inverse links}{prop.2}{}}
\newlabel{eq:mainineq}{{4}{6}{Proof of Proposition~\ref {prop:polynomial}}{equation.0.4}{}}
\citation{wang2008probability}
\citation{wang2008probability}
\citation{wang2008probability}
\MT@newlabel{eq:mainineq}
\MT@newlabel{eq:mainineq}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.4}Proof of Theorem\nobreakspace  {}\ref  {thm:main}}{7}{subsubsection.0.3.4}}
\newlabel{eq:rate}{{5}{8}{Proof of Theorem~\ref {thm:main}}{equation.0.5}{}}
\MT@newlabel{eq:excess-hinge}
\MT@newlabel{eq:rate}
\newlabel{eq:equation}{{6}{8}{Proof of Theorem~\ref {thm:main}}{equation.0.6}{}}
\MT@newlabel{eq:equation}
\MT@newlabel{eq:equation}
\MT@newlabel{eq:equation}
\newlabel{eq:delta}{{7}{8}{Proof of Theorem~\ref {thm:main}}{equation.0.7}{}}
\MT@newlabel{eq:delta}
\MT@newlabel{eq:rate}
\newlabel{eq:tail}{{C.4}{8}{Proof of Theorem~\ref {thm:main}}{equation.0.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {C.5}Proofs of Theorem\nobreakspace  {}\ref  {thm:regression}}{8}{subsubsection.0.3.5}}
\newlabel{lem:main}{{1}{8}{Multiple level-sets estimation}{lem.1}{}}
\newlabel{eq:total}{{8}{8}{Multiple level-sets estimation}{equation.0.8}{}}
\newlabel{eq:conversion2}{{9}{9}{Proofs of Theorem~\ref {thm:regression}}{equation.0.9}{}}
\MT@newlabel{eq:conversion2}
\MT@newlabel{eq:total}
\newlabel{eq:twobounds}{{10}{9}{Proofs of Theorem~\ref {thm:regression}}{equation.0.10}{}}
\MT@newlabel{eq:twobounds}
\newlabel{lem:H}{{2}{10}{}{lem.2}{}}
\newlabel{prop:equivalance}{{3}{10}{}{prop.3}{}}
\newlabel{eq:conversion}{{1}{10}{}{Item.7}{}}
\MT@newlabel{eq:excess-hinge}
\newlabel{eq:levelreg}{{C.5}{12}{Proofs of Theorem~\ref {thm:regression}}{Item.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {D}Auxiliary lemmas}{13}{subsection.0.4}}
\newlabel{lem:hingeL1}{{3}{13}{Hinge excess loss and $L$-1 distance}{lem.3}{}}
\newlabel{eq:function}{{11}{13}{Auxiliary lemmas}{equation.0.11}{}}
\MT@newlabel{eq:function}
\MT@newlabel{eq:function}
\MT@newlabel{eq:function}
\MT@newlabel{eq:function}
\newlabel{eq:integral}{{D}{14}{Auxiliary lemmas}{equation.0.11}{}}
\MT@newlabel{eq:prob2}
\newlabel{lem:product}{{4}{14}{Expectation of function products}{lem.4}{}}
\newlabel{eq:prob2}{{12}{15}{Expectation of function products}{equation.0.12}{}}
\MT@newlabel{eq:prob2}
\newlabel{eq:lowerbound}{{13}{15}{Auxiliary lemmas}{equation.0.13}{}}
\MT@newlabel{eq:prob2}
\MT@newlabel{eq:lowerbound}
\MT@newlabel{eq:lowerbound}
\newlabel{pro:inftynorm}{{1}{15}{Bracketing number}{defn.1}{}}
\citation{kosorok2007introduction}
\citation{candes2011tight}
\newlabel{lem:entropy}{{5}{16}{Bracketing number for bounded functions in $\tF (r,s_1,s_2)$}{lem.5}{}}
\MT@newlabel{eq:class}
\newlabel{lem:metric}{{6}{17}{Local complexity of $\tF (r,s_1,s_2)$}{lem.6}{}}
\newlabel{eq:specification}{{6}{17}{Local complexity of $\tF (r,s_1,s_2)$}{lem.6}{}}
\newlabel{eq:complexity}{{D}{17}{Auxiliary lemmas}{lem.6}{}}
\newlabel{eq:g}{{14}{17}{Auxiliary lemmas}{equation.0.14}{}}
\MT@newlabel{eq:g}
